{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ami-Br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 00:36:20,523 - INFO - Loading pretrained weights from Hugging Face hub (paige-ai/Virchow2)\n",
      "2025-07-13 00:36:20,680 - INFO - [paige-ai/Virchow2] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "Extracting embeddings: 100%|██████████| 826/826 [00:10<00:00, 80.65it/s]\n",
      "/tmp/ipykernel_3393218/1765217219.py:110: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 1 Inference: 100%|██████████| 52/52 [00:00<00:00, 169.36it/s]\n",
      "2025-07-13 00:36:31,898 - INFO - Fold 1 - Balanced Accuracy: 0.5743, AUROC: 0.6266, PR AUC: 0.8418\n",
      "Fold 2 Inference: 100%|██████████| 52/52 [00:00<00:00, 220.64it/s]\n",
      "2025-07-13 00:36:32,220 - INFO - Fold 2 - Balanced Accuracy: 0.6043, AUROC: 0.6670, PR AUC: 0.8611\n",
      "Fold 3 Inference: 100%|██████████| 52/52 [00:00<00:00, 223.40it/s]\n",
      "2025-07-13 00:36:32,508 - INFO - Fold 3 - Balanced Accuracy: 0.6281, AUROC: 0.6903, PR AUC: 0.8694\n",
      "Fold 4 Inference: 100%|██████████| 52/52 [00:00<00:00, 226.18it/s]\n",
      "2025-07-13 00:36:32,824 - INFO - Fold 4 - Balanced Accuracy: 0.6137, AUROC: 0.6582, PR AUC: 0.8569\n",
      "Fold 5 Inference: 100%|██████████| 52/52 [00:00<00:00, 226.34it/s]\n",
      "2025-07-13 00:36:33,110 - INFO - Fold 5 - Balanced Accuracy: 0.6241, AUROC: 0.6766, PR AUC: 0.8670\n",
      "2025-07-13 00:36:33,209 - INFO - \n",
      "--- Per-Fold Evaluation Summary (Virchow2 Linear Probing) ---\n",
      "2025-07-13 00:36:33,210 - INFO - Balanced Accuracy: 0.6089 ± 0.0192\n",
      "2025-07-13 00:36:33,210 - INFO - AUROC: 0.6637 ± 0.0214\n",
      "2025-07-13 00:36:33,210 - INFO - PR AUC: 0.8592 ± 0.0098\n",
      "2025-07-13 00:36:33,211 - INFO - Saved prediction results to: virchow2_amibr_test_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "\n",
    "# Logging setup\n",
    "log_file = \"virchow2_linear_probe_inference.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler(log_file), logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hugging Face login\n",
    "login(token=\"Your HuggingFace Token Here\")\n",
    "\n",
    "# Load Virchow2 feature extractor\n",
    "virchow_model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "virchow_model.eval().to(device)\n",
    "virchow_config = resolve_data_config(virchow_model.pretrained_cfg, model=virchow_model)\n",
    "virchow_transform = create_transform(**virchow_config)\n",
    "\n",
    "# Classifier head\n",
    "class VirchowBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VirchowBinaryClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(2560, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Embedding extractor\n",
    "def extract_embedding(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image_tensor = virchow_transform(image).unsqueeze(0).to(device)\n",
    "    with torch.inference_mode(), torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "        output = virchow_model(image_tensor)\n",
    "        class_token = output[:, 0]\n",
    "        patch_tokens = output[:, 5:]\n",
    "        embedding = torch.cat([class_token, patch_tokens.mean(1)], dim=-1).squeeze(0).to(torch.float32)\n",
    "    return embedding.cpu()\n",
    "\n",
    "# Inference dataset\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.embeddings = self._extract_all_embeddings()\n",
    "\n",
    "    def _extract_all_embeddings(self):\n",
    "        embeddings = []\n",
    "        for path in tqdm(self.image_paths, desc=\"Extracting embeddings\"):\n",
    "            embeddings.append(extract_embedding(path))\n",
    "        return embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Prepare test data\n",
    "test_root = \"/data/MELBA-AmiBr/Datasets_Stratified/AMi-Br/Test\"\n",
    "class_map = {\"Atypical\": 0, \"Normal\": 1}\n",
    "image_paths, labels = [], []\n",
    "\n",
    "for label_name, label_val in class_map.items():\n",
    "    class_dir = os.path.join(test_root, label_name)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "            image_paths.append(os.path.join(class_dir, fname))\n",
    "            labels.append(label_val)\n",
    "\n",
    "# Dataset and Dataloader\n",
    "test_dataset = InferenceDataset(image_paths, labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "# Load saved models\n",
    "num_folds = 5\n",
    "fold_models = []\n",
    "for i in range(num_folds):\n",
    "    model_path = f\"virchow2_linear_probe_fold_{i + 1}_best.pth\"\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.eval()\n",
    "    fold_models.append(model)\n",
    "\n",
    "# Ensure PR curve directory\n",
    "os.makedirs(\"pr_curves\", exist_ok=True)\n",
    "\n",
    "# Evaluation\n",
    "true_labels = np.array(test_dataset.labels)\n",
    "fold_bal_accs, fold_aurocs, fold_pr_aucs = [], [], []\n",
    "fold_probs_dict = {}\n",
    "all_precisions, all_recalls = [], []\n",
    "\n",
    "for i, model in enumerate(fold_models):\n",
    "    fold_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for embeddings, _ in tqdm(test_loader, desc=f\"Fold {i + 1} Inference\"):\n",
    "            embeddings = embeddings.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            probs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
    "            fold_probs.extend(probs)\n",
    "\n",
    "    fold_probs = np.array(fold_probs)\n",
    "    fold_preds = (fold_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    bal_acc = balanced_accuracy_score(true_labels, fold_preds)\n",
    "    auroc = roc_auc_score(true_labels, fold_probs)\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, fold_probs)\n",
    "    pr_auc = average_precision_score(true_labels, fold_probs)\n",
    "\n",
    "    # Log & store\n",
    "    logger.info(f\"Fold {i + 1} - Balanced Accuracy: {bal_acc:.4f}, AUROC: {auroc:.4f}, PR AUC: {pr_auc:.4f}\")\n",
    "    fold_bal_accs.append(bal_acc)\n",
    "    fold_aurocs.append(auroc)\n",
    "    fold_pr_aucs.append(pr_auc)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "\n",
    "    # Save predictions\n",
    "    fold_probs_dict[f\"fold_{i + 1}\"] = {\n",
    "        \"probs\": fold_probs,\n",
    "        \"preds\": fold_preds,\n",
    "        \"true_labels\": true_labels\n",
    "    }\n",
    "\n",
    "    # PR Curve plot\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f'Fold {i + 1} (AP = {pr_auc:.4f})')\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"Precision-Recall Curve - Fold {i + 1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"pr_curves/virchow2_amibr_pr_curve_fold_{i + 1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Mean PR curve (interpolated)\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "all_recalls_uniform = np.linspace(0, 1, 1000)\n",
    "interp_precisions = []\n",
    "\n",
    "for prec, rec in zip(all_precisions, all_recalls):\n",
    "    interp = interp1d(rec[::-1], prec[::-1], bounds_error=False, fill_value=0.0)\n",
    "    interp_precisions.append(interp(all_recalls_uniform))\n",
    "\n",
    "mean_precision = np.mean(interp_precisions, axis=0)\n",
    "\n",
    "# Plot average PR curve\n",
    "plt.figure()\n",
    "plt.plot(all_recalls_uniform, mean_precision, label=f\"Mean PR Curve (Avg AUC = {np.mean(fold_pr_aucs):.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Average Precision-Recall Curve (Virchow2 Linear Probing)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pr_curves/virchow2_amibr_pr_curve_average.png\")\n",
    "plt.close()\n",
    "\n",
    "# Final Summary\n",
    "logger.info(\"\\n--- Per-Fold Evaluation Summary (Virchow2 Linear Probing) ---\")\n",
    "logger.info(f\"Balanced Accuracy: {np.mean(fold_bal_accs):.4f} ± {np.std(fold_bal_accs):.4f}\")\n",
    "logger.info(f\"AUROC: {np.mean(fold_aurocs):.4f} ± {np.std(fold_aurocs):.4f}\")\n",
    "logger.info(f\"PR AUC: {np.mean(fold_pr_aucs):.4f} ± {np.std(fold_pr_aucs):.4f}\")\n",
    "\n",
    "# Save predictions\n",
    "output_path = \"virchow2_amibr_test_predictions.pkl\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(fold_probs_dict, f)\n",
    "\n",
    "logger.info(f\"Saved prediction results to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AtNorM-Br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:50:38,213 - INFO - Loading pretrained weights from Hugging Face hub (paige-ai/Virchow2)\n",
      "2025-07-13 13:50:38,340 - INFO - [paige-ai/Virchow2] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-07-13 13:50:40,322 - INFO - \n",
      "--- Fold 1 ---\n",
      "/tmp/ipykernel_3879013/3833765412.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 1 Inference: 100%|██████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "2025-07-13 13:51:16,877 - INFO - Balanced Accuracy: 0.5685, AUROC: 0.6132, PR AUC: 0.8806\n",
      "2025-07-13 13:51:16,931 - INFO - \n",
      "--- Fold 2 ---\n",
      "/tmp/ipykernel_3879013/3833765412.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 2 Inference: 100%|██████████| 94/94 [00:32<00:00,  2.85it/s]\n",
      "2025-07-13 13:51:49,877 - INFO - Balanced Accuracy: 0.6249, AUROC: 0.6901, PR AUC: 0.9125\n",
      "2025-07-13 13:51:49,924 - INFO - \n",
      "--- Fold 3 ---\n",
      "/tmp/ipykernel_3879013/3833765412.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 3 Inference: 100%|██████████| 94/94 [00:36<00:00,  2.59it/s]\n",
      "2025-07-13 13:52:26,288 - INFO - Balanced Accuracy: 0.6260, AUROC: 0.7075, PR AUC: 0.9121\n",
      "2025-07-13 13:52:26,335 - INFO - \n",
      "--- Fold 4 ---\n",
      "/tmp/ipykernel_3879013/3833765412.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 4 Inference: 100%|██████████| 94/94 [00:36<00:00,  2.57it/s]\n",
      "2025-07-13 13:53:02,950 - INFO - Balanced Accuracy: 0.6461, AUROC: 0.6825, PR AUC: 0.9024\n",
      "2025-07-13 13:53:02,996 - INFO - \n",
      "--- Fold 5 ---\n",
      "/tmp/ipykernel_3879013/3833765412.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 5 Inference: 100%|██████████| 94/94 [00:36<00:00,  2.58it/s]\n",
      "2025-07-13 13:53:39,376 - INFO - Balanced Accuracy: 0.6523, AUROC: 0.7044, PR AUC: 0.9115\n",
      "2025-07-13 13:53:39,471 - INFO - \n",
      "--- Final Evaluation ---\n",
      "2025-07-13 13:53:39,472 - INFO - Balanced Accuracy: 0.6236 ± 0.0296\n",
      "2025-07-13 13:53:39,472 - INFO - AUROC: 0.6795 ± 0.0344\n",
      "2025-07-13 13:53:39,472 - INFO - PR AUC: 0.9038 ± 0.0122\n",
      "2025-07-13 13:53:39,473 - INFO - Saved predictions to virchow2_atnorm-br_test_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Logging setup\n",
    "log_file = \"virchow2_linear_probe_inference.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler(log_file), logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hugging Face login\n",
    "login(token=\"Your HuggingFace Token Here\")\n",
    "\n",
    "# Load Virchow2 feature extractor\n",
    "virchow_model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "virchow_model.eval().to(device)\n",
    "virchow_config = resolve_data_config(virchow_model.pretrained_cfg, model=virchow_model)\n",
    "virchow_transform = create_transform(**virchow_config)\n",
    "\n",
    "# Classifier head definition\n",
    "class VirchowBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VirchowBinaryClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(2560, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Embedding extractor\n",
    "def extract_embedding(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image_tensor = virchow_transform(image).unsqueeze(0).to(device)\n",
    "    with torch.inference_mode():\n",
    "        output = virchow_model(image_tensor)\n",
    "        class_token = output[:, 0]\n",
    "        patch_tokens = output[:, 5:]\n",
    "        embedding = torch.cat([class_token, patch_tokens.mean(1)], dim=-1).squeeze(0).to(torch.float32)\n",
    "    return embedding.cpu()\n",
    "\n",
    "# Dataset\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = extract_embedding(self.image_paths[idx])\n",
    "        return embedding, self.labels[idx]\n",
    "\n",
    "# Prepare test data\n",
    "test_root = \"/data/MELBA-AmiBr/Datasets_Stratified/AtNorM-Br\"\n",
    "class_map = {\"Atypical\": 0, \"Normal\": 1}\n",
    "image_paths, labels = [], []\n",
    "\n",
    "for label_name, label_val in class_map.items():\n",
    "    class_dir = os.path.join(test_root, label_name)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "            image_paths.append(os.path.join(class_dir, fname))\n",
    "            labels.append(label_val)\n",
    "\n",
    "test_dataset = InferenceDataset(image_paths, labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Setup\n",
    "num_folds = 5\n",
    "true_labels = np.array(labels)\n",
    "fold_bal_accs, fold_aurocs, fold_pr_aucs = [], [], []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "fold_probs_dict = {}\n",
    "\n",
    "os.makedirs(\"pr_curves\", exist_ok=True)\n",
    "\n",
    "# Loop over folds\n",
    "for i in range(num_folds):\n",
    "    logger.info(f\"\\n--- Fold {i + 1} ---\")\n",
    "    model_path = f\"virchow2_linear_probe_fold_{i + 1}_best.pth\"\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.eval().to(device)\n",
    "\n",
    "    fold_probs = []\n",
    "    with torch.inference_mode():\n",
    "        for embeddings, _ in tqdm(test_loader, desc=f\"Fold {i + 1} Inference\"):\n",
    "            embeddings = embeddings.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            probs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
    "            fold_probs.extend(probs)\n",
    "\n",
    "    fold_probs = np.array(fold_probs)\n",
    "    fold_preds = (fold_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    bal_acc = balanced_accuracy_score(true_labels, fold_preds)\n",
    "    auroc = roc_auc_score(true_labels, fold_probs)\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, fold_probs)\n",
    "    pr_auc = average_precision_score(true_labels, fold_probs)\n",
    "\n",
    "    logger.info(f\"Balanced Accuracy: {bal_acc:.4f}, AUROC: {auroc:.4f}, PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    fold_bal_accs.append(bal_acc)\n",
    "    fold_aurocs.append(auroc)\n",
    "    fold_pr_aucs.append(pr_auc)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "\n",
    "    fold_probs_dict[f\"fold_{i + 1}\"] = {\n",
    "        \"probs\": fold_probs,\n",
    "        \"preds\": fold_preds,\n",
    "        \"true_labels\": true_labels\n",
    "    }\n",
    "\n",
    "    # PR Curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"Fold {i + 1} (AP={pr_auc:.4f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"PR Curve - Fold {i + 1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"pr_curves/virchow2_atnorm-br_pr_curve_fold_{i + 1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Delete model & free memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Average PR curve\n",
    "recalls_uniform = np.linspace(0, 1, 1000)\n",
    "interpolated = []\n",
    "for p, r in zip(all_precisions, all_recalls):\n",
    "    f = interp1d(r[::-1], p[::-1], bounds_error=False, fill_value=0.0)\n",
    "    interpolated.append(f(recalls_uniform))\n",
    "\n",
    "mean_precision = np.mean(interpolated, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recalls_uniform, mean_precision, label=f\"Mean PR (Avg AUC={np.mean(fold_pr_aucs):.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Average PR Curve - Virchow2 Linear Probe\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pr_curves/virchow2_atnorm-br_pr_curve_average.png\")\n",
    "plt.close()\n",
    "\n",
    "# Final summary\n",
    "logger.info(\"\\n--- Final Evaluation ---\")\n",
    "logger.info(f\"Balanced Accuracy: {np.mean(fold_bal_accs):.4f} ± {np.std(fold_bal_accs):.4f}\")\n",
    "logger.info(f\"AUROC: {np.mean(fold_aurocs):.4f} ± {np.std(fold_aurocs):.4f}\")\n",
    "logger.info(f\"PR AUC: {np.mean(fold_pr_aucs):.4f} ± {np.std(fold_pr_aucs):.4f}\")\n",
    "\n",
    "# Save prediction dict\n",
    "output_path = \"virchow2_atnorm-br_test_predictions.pkl\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(fold_probs_dict, f)\n",
    "\n",
    "logger.info(f\"Saved predictions to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AtNorM-MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 13:53:55,601 - INFO - Loading pretrained weights from Hugging Face hub (paige-ai/Virchow2)\n",
      "2025-07-13 13:53:55,727 - INFO - [paige-ai/Virchow2] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-07-13 13:53:57,837 - INFO - \n",
      "--- Fold 1 ---\n",
      "/tmp/ipykernel_3881805/4215574503.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 1 Inference: 100%|██████████| 264/264 [01:52<00:00,  2.35it/s]\n",
      "2025-07-13 13:55:50,004 - INFO - Balanced Accuracy: 0.5456, AUROC: 0.5409, PR AUC: 0.9060\n",
      "2025-07-13 13:55:50,076 - INFO - \n",
      "--- Fold 2 ---\n",
      "/tmp/ipykernel_3881805/4215574503.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 2 Inference: 100%|██████████| 264/264 [01:51<00:00,  2.36it/s]\n",
      "2025-07-13 13:57:41,988 - INFO - Balanced Accuracy: 0.5894, AUROC: 0.6165, PR AUC: 0.9266\n",
      "2025-07-13 13:57:42,032 - INFO - \n",
      "--- Fold 3 ---\n",
      "/tmp/ipykernel_3881805/4215574503.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 3 Inference: 100%|██████████| 264/264 [01:42<00:00,  2.57it/s]\n",
      "2025-07-13 13:59:24,783 - INFO - Balanced Accuracy: 0.5836, AUROC: 0.6266, PR AUC: 0.9291\n",
      "2025-07-13 13:59:24,828 - INFO - \n",
      "--- Fold 4 ---\n",
      "/tmp/ipykernel_3881805/4215574503.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 4 Inference: 100%|██████████| 264/264 [01:42<00:00,  2.58it/s]\n",
      "2025-07-13 14:01:07,315 - INFO - Balanced Accuracy: 0.5523, AUROC: 0.6115, PR AUC: 0.9281\n",
      "2025-07-13 14:01:07,364 - INFO - \n",
      "--- Fold 5 ---\n",
      "/tmp/ipykernel_3881805/4215574503.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=device)\n",
      "Fold 5 Inference: 100%|██████████| 264/264 [01:42<00:00,  2.57it/s]\n",
      "2025-07-13 14:02:50,130 - INFO - Balanced Accuracy: 0.5759, AUROC: 0.6274, PR AUC: 0.9325\n",
      "2025-07-13 14:02:50,220 - INFO - \n",
      "--- Final Evaluation ---\n",
      "2025-07-13 14:02:50,220 - INFO - Balanced Accuracy: 0.5694 ± 0.0173\n",
      "2025-07-13 14:02:50,220 - INFO - AUROC: 0.6046 ± 0.0324\n",
      "2025-07-13 14:02:50,221 - INFO - PR AUC: 0.9245 ± 0.0094\n",
      "2025-07-13 14:02:50,221 - INFO - Saved predictions to virchow2_atnorm-md_test_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import login\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.layers import SwiGLUPacked\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Logging setup\n",
    "log_file = \"virchow2_linear_probe_inference.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.FileHandler(log_file), logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hugging Face login\n",
    "login(token=\"Your HuggingFace Token Here\")\n",
    "\n",
    "# Load Virchow2 feature extractor\n",
    "virchow_model = timm.create_model(\n",
    "    \"hf-hub:paige-ai/Virchow2\",\n",
    "    pretrained=True,\n",
    "    mlp_layer=SwiGLUPacked,\n",
    "    act_layer=torch.nn.SiLU\n",
    ")\n",
    "virchow_model.eval().to(device)\n",
    "virchow_config = resolve_data_config(virchow_model.pretrained_cfg, model=virchow_model)\n",
    "virchow_transform = create_transform(**virchow_config)\n",
    "\n",
    "# Classifier head definition\n",
    "class VirchowBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VirchowBinaryClassifier, self).__init__()\n",
    "        self.classifier = nn.Linear(2560, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Embedding extractor\n",
    "def extract_embedding(img_path):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image_tensor = virchow_transform(image).unsqueeze(0).to(device)\n",
    "    with torch.inference_mode():\n",
    "        output = virchow_model(image_tensor)\n",
    "        class_token = output[:, 0]\n",
    "        patch_tokens = output[:, 5:]\n",
    "        embedding = torch.cat([class_token, patch_tokens.mean(1)], dim=-1).squeeze(0).to(torch.float32)\n",
    "    return embedding.cpu()\n",
    "\n",
    "# Dataset\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embedding = extract_embedding(self.image_paths[idx])\n",
    "        return embedding, self.labels[idx]\n",
    "\n",
    "# Prepare test data\n",
    "test_root = \"/data/MELBA-AmiBr/Datasets_Stratified/AtNorM-MD\"\n",
    "class_map = {\"Atypical\": 0, \"Normal\": 1}\n",
    "image_paths, labels = [], []\n",
    "\n",
    "for label_name, label_val in class_map.items():\n",
    "    class_dir = os.path.join(test_root, label_name)\n",
    "    for fname in os.listdir(class_dir):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png', '.tif')):\n",
    "            image_paths.append(os.path.join(class_dir, fname))\n",
    "            labels.append(label_val)\n",
    "\n",
    "test_dataset = InferenceDataset(image_paths, labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Setup\n",
    "num_folds = 5\n",
    "true_labels = np.array(labels)\n",
    "fold_bal_accs, fold_aurocs, fold_pr_aucs = [], [], []\n",
    "all_precisions = []\n",
    "all_recalls = []\n",
    "fold_probs_dict = {}\n",
    "\n",
    "os.makedirs(\"pr_curves\", exist_ok=True)\n",
    "\n",
    "# Loop over folds\n",
    "for i in range(num_folds):\n",
    "    logger.info(f\"\\n--- Fold {i + 1} ---\")\n",
    "    model_path = f\"virchow2_linear_probe_fold_{i + 1}_best.pth\"\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.eval().to(device)\n",
    "\n",
    "    fold_probs = []\n",
    "    with torch.inference_mode():\n",
    "        for embeddings, _ in tqdm(test_loader, desc=f\"Fold {i + 1} Inference\"):\n",
    "            embeddings = embeddings.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            probs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
    "            fold_probs.extend(probs)\n",
    "\n",
    "    fold_probs = np.array(fold_probs)\n",
    "    fold_preds = (fold_probs > 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    bal_acc = balanced_accuracy_score(true_labels, fold_preds)\n",
    "    auroc = roc_auc_score(true_labels, fold_probs)\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, fold_probs)\n",
    "    pr_auc = average_precision_score(true_labels, fold_probs)\n",
    "\n",
    "    logger.info(f\"Balanced Accuracy: {bal_acc:.4f}, AUROC: {auroc:.4f}, PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    fold_bal_accs.append(bal_acc)\n",
    "    fold_aurocs.append(auroc)\n",
    "    fold_pr_aucs.append(pr_auc)\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "\n",
    "    fold_probs_dict[f\"fold_{i + 1}\"] = {\n",
    "        \"probs\": fold_probs,\n",
    "        \"preds\": fold_preds,\n",
    "        \"true_labels\": true_labels\n",
    "    }\n",
    "\n",
    "    # PR Curve\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f\"Fold {i + 1} (AP={pr_auc:.4f})\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(f\"PR Curve - Fold {i + 1}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"pr_curves/virchow2_atnorm-md_pr_curve_fold_{i + 1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Delete model & free memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Average PR curve\n",
    "recalls_uniform = np.linspace(0, 1, 1000)\n",
    "interpolated = []\n",
    "for p, r in zip(all_precisions, all_recalls):\n",
    "    f = interp1d(r[::-1], p[::-1], bounds_error=False, fill_value=0.0)\n",
    "    interpolated.append(f(recalls_uniform))\n",
    "\n",
    "mean_precision = np.mean(interpolated, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recalls_uniform, mean_precision, label=f\"Mean PR (Avg AUC={np.mean(fold_pr_aucs):.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Average PR Curve - Virchow2 Linear Probe\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pr_curves/virchow2_atnorm-md_pr_curve_average.png\")\n",
    "plt.close()\n",
    "\n",
    "# Final summary\n",
    "logger.info(\"\\n--- Final Evaluation ---\")\n",
    "logger.info(f\"Balanced Accuracy: {np.mean(fold_bal_accs):.4f} ± {np.std(fold_bal_accs):.4f}\")\n",
    "logger.info(f\"AUROC: {np.mean(fold_aurocs):.4f} ± {np.std(fold_aurocs):.4f}\")\n",
    "logger.info(f\"PR AUC: {np.mean(fold_pr_aucs):.4f} ± {np.std(fold_pr_aucs):.4f}\")\n",
    "\n",
    "# Save prediction dict\n",
    "output_path = \"virchow2_atnorm-md_test_predictions.pkl\"\n",
    "with open(output_path, \"wb\") as f:\n",
    "    pickle.dump(fold_probs_dict, f)\n",
    "\n",
    "logger.info(f\"Saved predictions to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melbaAmiBr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
